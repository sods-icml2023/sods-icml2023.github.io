---
layout: post
title: Overview
permalink: /overview/
---

<!-- **Date and time:** May 7, time 8:45am-5:00pm PDT (see [schedule](https://simdl.github.io/schedule/)) <br>
The workshop will be held **virtually** at [https://iclr.cc/virtual/2021/workshop/2141](https://iclr.cc/virtual/2021/workshop/2141). The full recorded workshop will be open to general public some time later after the ICLR conference. If you would like to participate, you need to [register the ICLR ticket](https://iclr.cc/Conferences/2021) first. -->


In recent years, graph learning has quickly grown into an established sub-field of machine learning. Researchers have been focusing on developing novel model architectures, theoretical understandings, scalable algorithms and systems, and successful applications across industry and science regarding graph learning. In fact, more than 5000 research papers related to graph learning have been published over the past year alone.

### Challenges
Despite the success, existing graph learning paradigms have not captured the full spectrum of relationships in the physical and the virtual worlds.
For example, in terms of applicability of graph learning algorithms, current graph learning paradigms are often restricted to datasets with explicit graph representations,
whereas recent works have shown promise of graph learning methods for applications without explicit graph representations.
In terms of usability, while popular graph learning libraries greatly facilitate the implementation of graph learning techniques,
finding the right graph representation and model architecture for a given use case still requires heavy expert knowledge.
Furthermore, in terms of generalizability, unlike domains such as computer vision and natural language processing where large-scale pre-trained models generalize across downstream applications with little to no fine-tuning and demonstrate impressive performance, such a paradigm has yet to succeed in the graph learning domain.

### Goal
The primary goal of this workshop is to expand the impact of graph learning beyond the current boundaries. 
We believe that graph, or relation data, is a universal language that can be used to describe the complex world.
Ultimately, we hope graph learning will become a generic tool for learning and understanding any type of (structured) data. 
We aim to present and discuss the new frontiers in graph learning with researchers and practitioners within and outside the graph learning community. 
New understandings of the current challenges, new perspectives regarding the future directions, and new solutions and applications as proof of concepts are highly welcomed.


### Scope and Topics
We welcome submissions regarding the new frontiers of graph learning, including but not limited to:
- *Graphs in the wild:* Graph learning for datasets and applications without explicit relational structure (e.g., images, text, audios, code). Novel ways of modeling structured/unstructured data as graphs are highly welcomed.

- *Graphs in ML:* Graph representations in general machine learning problems (e.g., neural architectures as graphs, relations among input data and learning tasks, graphs in large language models, etc.)

- *New oasis:* Graph learning methods that are significantly different from the current paradigms (e.g., large-scale pre-trained models, multi-task models, super scalable algorithms, etc.)

- *New capabilities:* Graph representation for knowledge discovery, optimization, causal inference, explainable ML, ML fairness, etc.

- *Novel applications:* Novel applications of graph learning in real-world industry and scientific domains. (e.g., graph learning for missing data imputation, program synthesis, etc.) 


Should you have any questions, please reach out to us via email:<br>
[glfrontiers@googlegroups.com
](mailto:glfrontiers@googlegroups.com)



<!-- 
### References
[1] P. Battaglia et al. Interaction networks for learning about objects, relations and physics. NeurIPS 2016. <br>
[2] K. T. Sch√ºtt et al. Schnet: A continuous-filter convolutional neural network for modeling quantum interactions. NeurIPS 2017.<br>
[3] A. Sanchez et al. Graph networks as learnable physics engines for inference and control. PMLR 2018.<br>
[4] A. Sanchez et al. Learning to simulate complex physics with graph networks. ICML 2020.<br>
[5] A Sneak Peek at 19 Science Simulations for the Summit Supercomputer in 2019 (from the Oak Ridge National Laboratory). <br>
[6] S. He et al. Learning to predict the cosmological structure formation. Proceedings of the National Academy of Sciences 2019.<br>
[7] V. Bapst et al. Unveiling the predictive power of static structure in glassy systems. Nature Physics 2020.<br>
[8] Z. Long et al. PDE-Net 2.0: Learning PDEs from data with a numeric-symbolic hybrid deep network. Journal of Computational Physics 2019.<br>
[9] R. Wang et al. Towards physics-informed deep learning for turbulent flow prediction. KDD 2020.<br>
[10] A. Mohan et al. Embedding hard physical constraints in convolutional neural networks for 3D turbulence. ICLR 2020 Workshop.<br>
[11] Y. Li et al. Learning compositional koopman operators for model-based control. ICLR 2020.<br>
[12] Peurifoy, John, et al. "Nanophotonic particle simulation and inverse design using artificial neural networks." Science advances 4.6 (2018): eaar4206. -->

### Sponsorship
*NeurIPS 2022 GLFrontiers Workshop is generously sponsored by Google.*
<img src="https://github.com/glfrontiers/glfrontiers.github.io/blob/master/images/google.png?raw=true" alt="Google sponsorship" width="250" height="85">

